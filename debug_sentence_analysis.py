#!/usr/bin/env python3
"""
Debug the sentence scoring and key terms extraction
"""

import sys
import os
sys.path.append(os.path.abspath('.'))

from proper_slm_summarizer import StateOfTheArtIndicSummarizer

def debug_sentence_analysis():
    """Debug sentence scoring and key terms"""
    
    # Initialize summarizer
    summarizer = StateOfTheArtIndicSummarizer()
    
    # User's example text
    text = """‡∞¢‡∞ø‡∞≤‡±ç‡∞≤‡±Ä ‡∞®‡∞ó‡∞∞‡∞Ç ‡∞≠‡∞æ‡∞∞‡∞§‡∞¶‡±á‡∞∂‡∞Ç‡∞≤‡±ã ‡∞µ‡∞æ‡∞Ø‡±Å ‡∞ï‡∞æ‡∞≤‡±Å‡∞∑‡±ç‡∞Ø‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞ï‡±á‡∞Ç‡∞¶‡±ç‡∞∞‡∞Ç‡∞ó‡∞æ ‡∞Æ‡∞æ‡∞∞‡∞ø‡∞Ç‡∞¶‡∞ø. ‡∞Æ‡±Å‡∞ñ‡±ç‡∞Ø‡∞Ç‡∞ó‡∞æ ‡∞∂‡±Ä‡∞§‡∞æ‡∞ï‡∞æ‡∞≤‡∞Ç‡∞≤‡±ã ‡∞µ‡∞æ‡∞Ø‡±Å ‡∞®‡∞æ‡∞£‡±ç‡∞Ø‡∞§ ‡∞§‡±Ä‡∞µ‡±ç‡∞∞‡∞Ç‡∞ó‡∞æ ‡∞™‡∞°‡∞ø‡∞™‡±ã‡∞Ø‡∞ø, ‡∞™‡±å‡∞≤‡±ç‡∞Ø‡±Ç‡∞∑‡∞®‡±ç‚Äå ‡∞ï‡∞Ç‡∞ü‡±ç‡∞∞‡±ã‡∞≤‡±ç ‡∞¨‡±ã‡∞∞‡±ç‡∞°‡±Å ‡∞∏‡±Ç‡∞ö‡∞ø‡∞Ç‡∞ö‡∞ø‡∞® ‡∞™‡±ç‡∞∞‡∞Æ‡∞æ‡∞£‡∞æ‡∞≤‡∞®‡±Å ‡∞Æ‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞π‡∞æ‡∞®‡∞ø‡∞ï‡∞∞‡∞Æ‡±à‡∞® ‡∞∏‡±ç‡∞•‡∞æ‡∞Ø‡∞ø‡∞ï‡∞ø ‡∞ö‡±á‡∞∞‡±Å‡∞ï‡±Å‡∞Ç‡∞ü‡±Å‡∞Ç‡∞¶‡∞ø. ‡∞™‡±ä‡∞ó‡∞Æ‡∞Ç‡∞ö‡±Å, ‡∞µ‡∞æ‡∞π‡∞®‡∞æ‡∞≤ ‡∞é‡∞ó‡±Å‡∞∞‡±Å‡∞§‡±Å‡∞®‡±ç‡∞® ‡∞™‡±ä‡∞ó, ‡∞™‡∞∞‡∞ø‡∞∂‡±ç‡∞∞‡∞Æ‡∞≤ ‡∞®‡±Å‡∞Ç‡∞ö‡∞ø ‡∞µ‡±Ü‡∞≤‡±Å‡∞µ‡∞°‡±á ‡∞Æ‡±Å‡∞∞‡∞ø‡∞ï‡∞ø‡∞µ‡∞æ‡∞Ø‡±Å‡∞µ‡±Å‡∞≤‡±Å, ‡∞®‡∞ø‡∞∞‡±ç‡∞Æ‡∞æ‡∞£ ‡∞ï‡∞æ‡∞∞‡±ç‡∞Ø‡∞ï‡±ç‡∞∞‡∞Æ‡∞æ‡∞≤ ‡∞ß‡±Ç‡∞≥‡∞ø ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞ö‡±Å‡∞ü‡±ç‡∞ü‡±Å‡∞™‡∞ï‡±ç‡∞ï‡∞≤ ‡∞∞‡∞æ‡∞∑‡±ç‡∞ü‡±ç‡∞∞‡∞æ‡∞≤ ‡∞®‡±Å‡∞Ç‡∞ö‡∞ø ‡∞µ‡∞ö‡±ç‡∞ö‡±á ‡∞™‡±ä‡∞≤‡∞æ‡∞≤ ‡∞ï‡∞æ‡∞≤‡±ç‡∞ö‡±á ‡∞¶‡±Å‡∞∑‡±ç‡∞™‡∞∞‡∞ø‡∞£‡∞æ‡∞Æ‡∞æ‡∞≤ ‡∞µ‡∞≤‡∞® ‡∞¢‡∞ø‡∞≤‡±ç‡∞≤‡±Ä ‡∞µ‡∞æ‡∞∏‡±Å‡∞≤‡±Å ‡∞Ü‡∞∞‡±ã‡∞ó‡±ç‡∞Ø ‡∞∏‡∞Æ‡∞∏‡±ç‡∞Ø‡∞≤‡∞®‡±Å ‡∞é‡∞¶‡±Å‡∞∞‡±ç‡∞ï‡±ä‡∞Ç‡∞ü‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞∞‡±Å. ‡∞™‡∞ø‡∞≤‡±ç‡∞≤‡∞≤‡±Å, ‡∞µ‡±É‡∞¶‡±ç‡∞ß‡±Å‡∞≤‡±Å ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞∂‡±ç‡∞µ‡∞æ‡∞∏‡∞ï‡±ã‡∞∂ ‡∞∏‡∞Ç‡∞¨‡∞Ç‡∞ß‡∞ø‡∞§ ‡∞∞‡±Å‡∞ó‡±ç‡∞Æ‡∞§‡∞≤‡±Å ‡∞â‡∞®‡±ç‡∞®‡∞µ‡∞æ‡∞∞‡±Å ‡∞§‡±Ä‡∞µ‡±ç‡∞∞‡∞Æ‡±à‡∞® ‡∞∏‡∞Æ‡∞∏‡±ç‡∞Ø‡∞≤‡∞ï‡±Å ‡∞ó‡±Å‡∞∞‡∞µ‡±Å‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞∞‡±Å. ‡∞™‡±ç‡∞∞‡∞≠‡±Å‡∞§‡±ç‡∞µ‡∞Ç ‡∞™‡±ç‡∞∞‡∞§‡±Ä‡∞µ‡±á‡∞≥ ‡∞µ‡∞ø‡∞™‡∞§‡±ç‡∞ï‡∞∞ ‡∞™‡∞∞‡∞ø‡∞∏‡±ç‡∞•‡∞ø‡∞§‡±Å‡∞≤‡±ç‡∞≤‡±ã ‡∞™‡∞æ‡∞†‡∞∂‡∞æ‡∞≤‡∞≤‡±Å ‡∞Æ‡±Ç‡∞∏‡∞ø‡∞µ‡±á‡∞Ø‡∞°‡∞Ç, ‡∞µ‡∞æ‡∞π‡∞®‡∞æ‡∞≤ ‡∞™‡∞∞‡∞ø‡∞Æ‡∞ø‡∞§ ‡∞µ‡∞ø‡∞®‡∞ø‡∞Ø‡±ã‡∞ó‡∞æ‡∞®‡∞ø‡∞ï‡∞ø '‡∞í‡∞°‡±ç ‡∞à‡∞µ‡±Ü‡∞®‡±ç' ‡∞µ‡∞ø‡∞ß‡∞æ‡∞®‡∞Ç, ‡∞®‡∞ø‡∞∞‡±ç‡∞Æ‡∞æ‡∞£‡∞æ‡∞≤‡∞™‡±à ‡∞®‡∞ø‡∞∑‡±á‡∞ß‡∞Ç ‡∞µ‡∞Ç‡∞ü‡∞ø ‡∞ö‡∞∞‡±ç‡∞Ø‡∞≤‡±Å ‡∞§‡±Ä‡∞∏‡±Å‡∞ï‡±Å‡∞Ç‡∞ü‡±Å‡∞®‡±ç‡∞®‡∞™‡±ç‡∞™‡∞ü‡∞ø‡∞ï‡±Ä ‡∞¶‡±Ä‡∞∞‡±ç‡∞ò‡∞ï‡∞æ‡∞≤‡∞ø‡∞ï ‡∞™‡∞∞‡∞ø‡∞∑‡±ç‡∞ï‡∞æ‡∞∞‡∞Ç ‡∞Æ‡∞æ‡∞§‡±ç‡∞∞‡∞Ç ‡∞ï‡∞®‡∞ø‡∞™‡∞ø‡∞Ç‡∞ö‡∞°‡∞Ç ‡∞≤‡±á‡∞¶‡±Å. ‡∞µ‡∞æ‡∞§‡∞æ‡∞µ‡∞∞‡∞£ ‡∞Æ‡∞æ‡∞∞‡±ç‡∞™‡±Å‡∞≤‡±Å, ‡∞ú‡∞®‡∞∏‡∞æ‡∞Ç‡∞¶‡±ç‡∞∞‡∞§ ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞Ü‡∞ß‡±Å‡∞®‡∞ø‡∞ï ‡∞ú‡±Ä‡∞µ‡∞®‡∞∂‡±à‡∞≤‡∞ø‡∞≤‡±ã‡∞®‡∞ø ‡∞Æ‡∞æ‡∞∞‡±ç‡∞™‡±Å‡∞≤‡±Å ‡∞à ‡∞∏‡∞Æ‡∞∏‡±ç‡∞Ø‡∞®‡±Å ‡∞Æ‡∞∞‡∞ø‡∞Ç‡∞§ ‡∞µ‡±á‡∞ó‡∞Ç‡∞ó‡∞æ ‡∞™‡±Ü‡∞Ç‡∞ö‡±Å‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞Ø‡∞ø. ‡∞ï‡∞æ‡∞≤‡±Å‡∞∑‡±ç‡∞Ø‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞®‡∞ø‡∞Ø‡∞Ç‡∞§‡±ç‡∞∞‡∞ø‡∞Ç‡∞ö‡±á‡∞Ç‡∞¶‡±Å‡∞ï‡±Å ‡∞™‡±ç‡∞∞‡∞≠‡±Å‡∞§‡±ç‡∞µ‡∞Ç, ‡∞™‡∞∞‡∞ø‡∞∂‡±ç‡∞∞‡∞Æ‡∞≤‡±Å ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞™‡±ç‡∞∞‡∞ú‡∞≤‡±Å ‡∞∏‡∞Æ‡∞ø‡∞∑‡±ç‡∞ü‡∞ø‡∞ó‡∞æ ‡∞µ‡±ç‡∞Ø‡∞µ‡∞π‡∞∞‡∞ø‡∞Ç‡∞ö‡∞æ‡∞≤‡±ç‡∞∏‡∞ø‡∞® ‡∞Ö‡∞µ‡∞∏‡∞∞‡∞Ç ‡∞é‡∞Ç‡∞§‡±ã ‡∞â‡∞Ç‡∞¶‡∞ø."""
    
    sentences = summarizer._preprocess_text(text)
    print(f"Number of sentences: {len(sentences)}")
    
    for i, sentence in enumerate(sentences):
        print(f"\n--- Sentence {i} ---")
        print(f"Text: {sentence}")
        print(f"Length: {len(sentence)} characters")
        
        # Get key terms
        key_terms = summarizer._get_sentence_key_terms(sentence)
        print(f"Key terms: {key_terms}")
        
        # Get sentence score components
        words = summarizer._tokenize_words(sentence)
        stopwords = summarizer.stopwords.get('te', set())
        words_filtered = [w.lower() for w in words if w.lower() not in stopwords]
        print(f"Content words: {words_filtered[:10]}...")  # Show first 10
        
    # Test with larger max_length
    print(f"\nüîç Testing with larger max_length (400):")
    extractive_summary = summarizer._enhanced_extractive_summarize(sentences, 400)
    print(f"Summary: {extractive_summary}")
    summary_sentences = summarizer._preprocess_text(extractive_summary)
    print(f"Number of sentences in summary: {len(summary_sentences)}")

if __name__ == "__main__":
    debug_sentence_analysis()
